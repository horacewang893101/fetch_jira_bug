# MP-467: Recommendation - Websocket CHAT API improvements

**Status:** Backlog

**Assignee:** Unassigned

**Description:**
Tokens are streamed, and then the full answer is sent again, which can lead to duplication, race conditions. The conversation flow looks like the following:
 stream → stream → stream → full answer
 

Instead, it is recommended to use a single streaming pipeline (assistant_delta events ending with assistant_done) and never resend the full message after streaming.  Messages have no identity or ordering. Streaming chunks and final messages lack stable IDs and sequence numbers, making reliable reconnection, deduplication, and concurrency impossible.
For example: 

{"message": "Hello", "status": "stream" }
 

Every response should have a message_id, and every streamed chunk should include an increasing sequence number so clients can reassemble and resume safely. 

Protocol semantics are unclear; the protocol mixes processing, stream, and answer states that overlap and do not define clear behavior.
For example: 

{"type": "bot", "category": "processing" }
 

Instead, using a small, explicit protocol such as auth, user_message, assistant_delta, assistant_done, and error is recommended. 
